{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f98925",
   "metadata": {},
   "source": [
    "## Experiment showing KSD's decay for on-target samples (the variance problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30662de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.distributions as dists\n",
    "from scem import loss, util, kernel, net, stein, cpdkernel\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import dirname, join\n",
    "import pickle\n",
    "import ksdmom.sampler as samp\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9062ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = './results/varshift'\n",
    "problem = 'Gaussian_ontarget'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = (join(results_path, problem))\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ea881",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66248b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\n",
    "    'family' : 'serif',\n",
    "#     'weight' : 'bold',\n",
    "    'size'   : 24\n",
    "}\n",
    "# matplotlib.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "\n",
    "matplotlib.rc('text', usetex=True)\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=3, markersize=10)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7a362",
   "metadata": {},
   "source": [
    "### Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ced63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal:\n",
    "    def __init__(self, m, s):\n",
    "        self.m = m \n",
    "        self.s = s\n",
    "    \n",
    "    def den(self, X):\n",
    "        m = self.m\n",
    "        s = self.s \n",
    "        \n",
    "        den = torch.exp(-torch.sum((X-m)**2, axis=1)/(2*s**2))\n",
    "        den /= (2*math.pi*s**2)**(d/2)\n",
    "        return den\n",
    "    \n",
    "    def log_den(self, X):\n",
    "        m = self.m\n",
    "        s = self.s\n",
    "        ld = -torch.sum((X-m)**2, axis=1)/(2*s**2)\n",
    "        ld -= d/2 * torch.log(torch.tensor(2*math.pi*s**2))\n",
    "        return ld\n",
    "    \n",
    "    def score(self, X):\n",
    "        m = self.m \n",
    "        s = self.s\n",
    "        return -(X-m) / s**2\n",
    "    \n",
    "    def sample(self, n):\n",
    "        m = self.m\n",
    "        d = len(m)\n",
    "        return m + self.s * torch.randn(n, d)\n",
    "    \n",
    "class MixNormal:\n",
    "    def __init__(self, m1, m2, s1, s2, mweights=None):\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.s1 = s1\n",
    "        self.s2 = s2\n",
    "        self.mweights = (mweights if mweights is not None else \n",
    "                         torch.ones(2)/2.)\n",
    "    \n",
    "    def score(self, X):\n",
    "        m1 = self.m1\n",
    "        m2 = self.m2\n",
    "        s1 = self.s1\n",
    "        s2 = self.s2\n",
    "        d = len(self.m1)\n",
    "        mweights = self.mweights\n",
    "\n",
    "        den1 = torch.exp(-torch.sum((X-m1)**2, axis=1)/(2*s1**2))\n",
    "        den1 /= (2*math.pi*s1**2)**(d/2)\n",
    "        den2 = torch.exp(-torch.sum((X-m2)**2, axis=1)/(2*s2**2))\n",
    "        den2 /= (2*math.pi*s2**2)**(d/2)\n",
    "\n",
    "        score1 = -(X - m1)/(s1**2) \n",
    "        score2 = -(X - m2)/(s2**2) \n",
    "        \n",
    "        post_prob1 = mweights[0] * den1 / (mweights[0]*den1 + mweights[1]*den2)\n",
    "        post_prob1 = post_prob1.unsqueeze(1)\n",
    "        post_prob2 = 1. - post_prob1\n",
    "        sc = post_prob1*score1 + post_prob2*score2\n",
    "        return sc\n",
    "    \n",
    "    def den(self, X):\n",
    "        m1 = self.m1\n",
    "        m2 = self.m2\n",
    "        s1 = self.s1\n",
    "        s2 = self.s2\n",
    "        d = len(self.m1)\n",
    "        w = self.mweights\n",
    "        den1 = torch.exp(-torch.sum((X-m1)**2, axis=1)/(2*s1**2))\n",
    "        den1 /= (2*math.pi*s1**2)**(d/2)\n",
    "        den2 = torch.exp(-torch.sum((X-m2)**2, axis=1)/(2*s2**2))\n",
    "        den2 /= (2*math.pi*s2**2)**(d/2)\n",
    "        return w[0]*den1 + w[1]*den2\n",
    "    \n",
    "    def log_den(self, X):\n",
    "        return torch.log(self.den(X))\n",
    "    \n",
    "    def sample(self, n):\n",
    "        m = torch.distributions.Binomial(n, torch.tensor([self.mweights[0]]))        \n",
    "        n1 = int(m.sample().item())\n",
    "        n2 = n - n1 \n",
    "        d = len(self.m1)\n",
    "        X1 = self.s1*torch.randn(n1, d) + self.m1\n",
    "        X2 = self.s2*torch.randn(n2, d) + self.m2\n",
    "        X = torch.cat([X1, X2])\n",
    "        for _ in range(30):\n",
    "            idx = torch.randperm(n)\n",
    "            X = X[idx]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = 1\n",
    "n_ps = 100\n",
    "d = 5\n",
    "m = torch.zeros(d)\n",
    "s = 1\n",
    "target = Normal(m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ed199",
   "metadata": {},
   "source": [
    "### Defining kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kimq  = kernel.KIMQ()\n",
    "loc = None\n",
    "klin = kernel.KLinear(scale=1, loc=loc, bias=1)\n",
    "w = kernel.MultiquadraticWeight(p=-0.5, bias=1, loc=loc)\n",
    "kw = kernel.KSTWeight(w_func=w)\n",
    "ktilted_lin = kernel.KSTProduct(klin, kw)\n",
    "ksum_imq = kernel.KSTSumKernel([ktilted_lin, kimq])\n",
    "\n",
    "w_ = kernel.MultiquadraticWeight(p=(1.+0.1)/2, bias=1, loc=loc)\n",
    "kw_ = kernel.KSTWeight(w_func=w_)\n",
    "kx = kernel.KSTProduct(ksum_imq, kw_)\n",
    "\n",
    "w_ = kernel.MultiquadraticWeight(p=(1.)/2, bias=1, loc=loc)\n",
    "kw_ = kernel.KSTWeight(w_func=w_)\n",
    "kx_zero = kernel.KSTProduct(ksum_imq, kw_)\n",
    "\n",
    "\n",
    "kmat = kernel.KMatern(scale=1)\n",
    "kmat_sum = kernel.KSTSumKernel([ktilted_lin, kimq])\n",
    "kmat_sum = kernel.KSTProduct(kmat_sum, kw_)\n",
    "\n",
    "kernels = {\n",
    "    'IMQ': kimq, \n",
    "    'IMQ-sum-quad-theta': kx,\n",
    "    'IMQ-sum-quad': kx_zero,\n",
    "    'IMQ-sum': ksum_imq,\n",
    "#     'Mat-sum': kmat_sum,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b20c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = False\n",
    "vstat = True\n",
    "\n",
    "n_ps = 30\n",
    "sample_sizes = torch.logspace(2, 4, n_ps)\n",
    "data = np.empty([len(kernels), rep, n_ps])\n",
    "losses = {\n",
    "    k: loss.KSD(v, target.score) \n",
    "    for k, v in kernels.items()\n",
    "}\n",
    "sampler = target\n",
    "for l_i, (key, l) in enumerate(losses.items()):\n",
    "    filename = (\n",
    "        '{}.npy'.format(key) if not vstat else\n",
    "        '{}_vstat.npy'.format(key)\n",
    "    )\n",
    "    path = os.path.join(dir_path, filename)\n",
    "    if os.path.exists(path) and not rerun:\n",
    "        tmp = np.load(path)\n",
    "        data[l_i] = tmp\n",
    "    else:\n",
    "        for j, n in enumerate(sample_sizes):\n",
    "            for i in range(rep):\n",
    "                X = sampler.sample(int(n.item()))\n",
    "                data[l_i, i, j] = l.loss(X, vstat=vstat).detach().numpy()\n",
    "        result = data[l_i]\n",
    "        np.save(path, result)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffbeda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Format = namedtuple('Format', ['color', 'linestyle'])\n",
    "label_format_tuples = {\n",
    "    'IMQ': (\"IMQ\", Format('C1', '-')),\n",
    "    'IMQ-sum': ('IMQ sum (lin.)  $\\\\theta=0$', Format('C2', '--')),\n",
    "    'IMQ-sum-quad-theta': ('IMQ sum (quad.) $\\\\theta=0.1$', Format('C5', '-.')),\n",
    "    'IMQ-sum-quad': ('IMQ sum (quad.)  $\\\\theta=0$', Format('C6', ':')),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2011812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import LogLocator\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "\n",
    "label = ax.set_xlabel('Sample size $N$', fontsize = 24)\n",
    "label = ax.set_ylabel('$\\\\mathrm{KSD}(P, P_N)^2$', fontsize = 24)\n",
    "label.set_rotation(0)\n",
    "ax.xaxis.set_label_coords(0.5, -0.15)\n",
    "ax.yaxis.set_label_coords(-0.1, 1.05)    \n",
    "\n",
    "ax.set_yticks([1e+0, 1e+1, 1e+2])\n",
    "\n",
    "ps = sample_sizes.detach().numpy()\n",
    "for ki, key in enumerate(losses.keys()):\n",
    "    label = label_format_tuples[key][0]\n",
    "    fmt = label_format_tuples[key][1]\n",
    "    y = data[ki].mean(axis=0)\n",
    "    ax.plot(ps, y, label=label, \n",
    "        color=fmt.color, linestyle=fmt.linestyle)\n",
    "\n",
    "# ax.legend(bbox_to_anchor=(1.75,1.), ncol=4)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "#ax.yaxis.set_minor_locator(LogLocator(numticks=10))\n",
    " \n",
    "plt.savefig('ksd_gauss_var_onsample.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
